input {
  tcp {
    port => 5000
    codec => json_lines {
      # Target field for parsed JSON
      target => "data"
    }
    add_field => { "[@metadata][input]" => "tcp" }
    tags => ["tcp-input", "eccs"]
  }
  
  beats {
    port => 5044
    add_field => { "[@metadata][input]" => "beats" }
    tags => ["beats-input", "eccs"]
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      skip_on_invalid_json => true
    }
  }

  # Flatten nested data from TCP input
  if [data] {
    ruby {
      code => '
        data = event.get("data")
        if data.is_a?(Hash)
          data.each { |k, v| event.set(k, v) }
        end
        event.remove("data")
      '
    }
  }

  # Extract service name and store in service_name field
  # Using service_name instead of service to avoid conflicts with ECS format
  # ECS uses service as an object (service.name, service.type), but our logs
  # send it as a string, causing Elasticsearch mapping conflicts.
  ruby {
    code => '
      service = event.get("service")
      
      if service
        if service.is_a?(Hash)
          extracted_name = service["name"] || service["serviceName"]
          if extracted_name
            event.set("service_name", extracted_name.to_s)
          else
            event.set("service_name", "unknown-service")
          end
        elsif service.is_a?(String)
          event.set("service_name", service)
        else
          event.set("service_name", service.to_s)
        end
        event.remove("service")
      elsif event.get("[container][name]")
        event.set("service_name", event.get("[container][name]"))
      else
        event.set("service_name", "unknown")
      end
      
      service_name = event.get("service_name")
      if service_name && service_name.start_with?("eccs-")
        event.set("service_name", service_name.sub(/^eccs-/, ""))
      end
    '
  }

  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
    target => "@timestamp"
    tag_on_failure => ["_timestamp_parse_failure"]
  }

  # Add geo information for IPs if present (skip private IPs)
  if [client_ip] and [client_ip] !~ /^(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.|127\.|::1|fc|fd)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
      tag_on_failure => ["_geoip_lookup_failure"]
    }
  }

  # Tag email-related logs
  if [service_name] =~ /email|notification/ {
    mutate {
      add_tag => ["email-service"]
    }
  }

  # Tag error logs
  if [level] == "error" or [level] == "ERROR" {
    mutate {
      add_tag => ["error"]
    }
  }

  # Parse error stack traces
  if [stack] or [stackTrace] or [error][stack_trace] {
    mutate {
      add_tag => ["has-stack-trace"]
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["@version", "[agent][ephemeral_id]", "[agent][id]"]
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:http://elasticsearch:9200}"]
    index => "eccs-logs-%{+YYYY.MM.dd}"
    retry_on_conflict => 3
    ilm_enabled => false
    manage_template => false
  }

  # Debug output (optional)
  # stdout { codec => rubydebug { metadata => true } }
}
